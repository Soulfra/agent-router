# CalOS Agent Router Configuration
# Copy this file to .env and configure as needed

# ========================================
# Local AI (RECOMMENDED - Works Offline!)
# ========================================

# Ollama URL (for fully local models - FREE and UNLIMITED!)
# Install: https://ollama.ai
# Start: `ollama serve`
# Models: `ollama pull mistral` or `ollama pull llama2`
OLLAMA_API_URL=http://localhost:11434

# ========================================
# Cloud AI Provider API Keys (OPTIONAL)
# ========================================
# NOTE: Cloud providers cost money and require internet.
# CalOS works 100% locally with Ollama - API keys are optional!
#
# Only configure these if you want to use cloud providers:

# OpenAI API Key (optional - costs money)
OPENAI_API_KEY=

# Anthropic API Key (optional - costs money)
ANTHROPIC_API_KEY=

# DeepSeek API Key (optional - costs money)
DEEPSEEK_API_KEY=

# ========================================
# Router Settings
# ========================================
PORT=5001
CORS_ORIGIN=*

# ========================================
# Database Configuration (for --local mode)
# ========================================

# Database Type: 'postgres' or 'sqlite'
DB_TYPE=postgres

# PostgreSQL Configuration (if DB_TYPE=postgres)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=calos
DB_USER=  # Leave empty to use current user (recommended)
DB_PASSWORD=

# SQLite Configuration (if DB_TYPE=sqlite)
DB_PATH=../memory/calos.db

# ========================================
# Usage:
# Normal mode:  npm start
# Local mode:   node router.js --local
# ========================================
