# CalOS Voice API - Platform Integration Guide

**Date:** 2025-10-15
**Status:** ‚úÖ All APIs Working & Tested

---

## Quick Links

- **PWA Voice Recorder**: http://127.0.0.1:5001/voice-recorder.html
- **API Base URL**: http://127.0.0.1:5001
- **SDK**: `sdk/voice-client.js`

---

## üéØ Tested & Working

### ‚úÖ API Endpoints (Real Responses)

```bash
# List projects
curl -H "X-User-Id: YOUR-USER-ID" \
  http://127.0.0.1:5001/api/voice/projects

# Response: {"total": 7, "projects": [...]}

# Cumulative stats
curl -H "X-User-Id: YOUR-USER-ID" \
  http://127.0.0.1:5001/api/voice/stats/cumulative

# Response: {"total_api_calls": 2, "total_tokens": 1462, ...}

# Daily stats
curl -H "X-User-Id: YOUR-USER-ID" \
  "http://127.0.0.1:5001/api/voice/stats/daily?from=2025-10-01&to=2025-10-15"

# Response: {"daily_stats": [...], "period_totals": {...}}
```

---

## üåê Web / PWA Integration

### Option 1: Use Pre-Built PWA

**Already deployed at**: `public/voice-recorder.html`

1. Open http://127.0.0.1:5001/voice-recorder.html
2. Enter your user_id (from login)
3. Tap to record
4. View real-time stats

**Features:**
- Web Audio API recording
- Automatic project detection
- Live usage statistics
- Works on mobile browsers (iOS Safari, Android Chrome)
- Installable as PWA (add to home screen)

### Option 2: Use SDK in Your Web App

```html
<script type="module">
  import CalOSVoiceClient from '/sdk/voice-client.js';

  const client = new CalOSVoiceClient({
    baseUrl: 'http://127.0.0.1:5001',
    userId: 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d'
  });

  // Record and transcribe
  const recorder = await client.recordAudio();

  // User records...

  recorder.stop();
  const audioBlob = await recorder;

  const result = await client.transcribe(audioBlob);
  console.log('Transcript:', result.data.transcript);
  console.log('Project:', result.data.project.project_name);

  // Get stats
  const stats = await client.getCumulativeStats();
  console.log('Total calls:', stats.data.total_api_calls);
</script>
```

### Option 3: Plain JavaScript (No SDK)

```javascript
// Record audio
const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
const recorder = new MediaRecorder(stream);
const chunks = [];

recorder.ondataavailable = e => chunks.push(e.data);
recorder.onstop = async () => {
  const blob = new Blob(chunks, { type: 'audio/webm' });

  // Upload
  const formData = new FormData();
  formData.append('audio', blob, 'recording.webm');

  const response = await fetch('/api/voice/yap', {
    method: 'POST',
    headers: {
      'X-User-Id': localStorage.getItem('user_id')
    },
    body: formData
  });

  const result = await response.json();
  console.log(result.data.transcript);
};

recorder.start();
// ... later ...
recorder.stop();
```

---

## üì± iOS Integration (Capacitor)

Your existing iOS app is already configured: `ios/App/App.xcodeproj`

### Method 1: WebView (Easiest)

```swift
// ios/App/App/ViewController.swift
import Capacitor

// Your web app already works in Capacitor WebView
// Just navigate to: http://localhost:5001/voice-recorder.html
```

**Already configured in** `capacitor.config.json`:
```json
{
  "server": {
    "url": "http://localhost:5001"
  }
}
```

### Method 2: Native Audio Plugin

Create a Capacitor plugin for native audio recording:

```swift
// ios/App/App/Plugins/VoiceRecorder.swift
import Foundation
import Capacitor
import AVFoundation

@objc(VoiceRecorderPlugin)
public class VoiceRecorderPlugin: CAPPlugin {
    var audioRecorder: AVAudioRecorder?

    @objc func startRecording(_ call: CAPPluginCall) {
        let audioSession = AVAudioSession.sharedInstance()

        do {
            try audioSession.setCategory(.record, mode: .default)
            try audioSession.setActive(true)

            let settings = [
                AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]

            let audioURL = getDocumentsDirectory().appendingPathComponent("recording.m4a")
            audioRecorder = try AVAudioRecorder(url: audioURL, settings: settings)
            audioRecorder?.record()

            call.resolve(["status": "recording"])
        } catch {
            call.reject("Failed to start recording", error)
        }
    }

    @objc func stopRecording(_ call: CAPPluginCall) {
        audioRecorder?.stop()
        let audioURL = getDocumentsDirectory().appendingPathComponent("recording.m4a")

        call.resolve([
            "status": "stopped",
            "filePath": audioURL.path
        ])
    }

    @objc func uploadRecording(_ call: CAPPluginCall) {
        guard let userId = call.getString("userId") else {
            call.reject("userId required")
            return
        }

        let audioURL = getDocumentsDirectory().appendingPathComponent("recording.m4a")

        var request = URLRequest(url: URL(string: "http://127.0.0.1:5001/api/voice/yap")!)
        request.httpMethod = "POST"
        request.setValue(userId, forHTTPHeaderField: "X-User-Id")

        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")

        var body = Data()
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"audio\"; filename=\"recording.m4a\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: audio/m4a\r\n\r\n".data(using: .utf8)!)
        body.append(try! Data(contentsOf: audioURL))
        body.append("\r\n--\(boundary)--\r\n".data(using: .utf8)!)

        request.httpBody = body

        URLSession.shared.dataTask(with: request) { data, response, error in
            if let data = data, let json = try? JSONSerialization.jsonObject(with: data) {
                call.resolve(json as! [String: Any])
            } else {
                call.reject("Upload failed", error)
            }
        }.resume()
    }

    private func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
}
```

**Register plugin** in `ios/App/App/Info.plist`:
```xml
<key>NSMicrophoneUsageDescription</key>
<string>We need microphone access to record voice notes</string>
```

**Use from JavaScript:**
```javascript
import { Plugins } from '@capacitor/core';
const { VoiceRecorder } = Plugins;

// Start recording
await VoiceRecorder.startRecording();

// Stop and upload
await VoiceRecorder.stopRecording();
await VoiceRecorder.uploadRecording({
  userId: 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d'
});
```

---

## ü§ñ Android Integration (Capacitor)

### Setup Android App

```bash
cd /Users/matthewmauer/Desktop/CALOS_ROOT/agent-router
npx cap add android
npx cap sync
```

### Method 1: WebView (Easiest)

Same as iOS - web app works automatically in Android WebView.

### Method 2: Native Audio Plugin

```kotlin
// android/app/src/main/java/com/calos/app/VoiceRecorderPlugin.kt
package com.calos.app

import android.media.MediaRecorder
import com.getcapacitor.Plugin
import com.getcapacitor.PluginCall
import com.getcapacitor.PluginMethod
import com.getcapacitor.annotation.CapacitorPlugin
import okhttp3.*
import java.io.File
import java.io.IOException

@CapacitorPlugin(name = "VoiceRecorder")
class VoiceRecorderPlugin : Plugin() {
    private var mediaRecorder: MediaRecorder? = null
    private var audioFile: File? = null

    @PluginMethod
    fun startRecording(call: PluginCall) {
        audioFile = File(context.cacheDir, "recording.m4a")

        mediaRecorder = MediaRecorder().apply {
            setAudioSource(MediaRecorder.AudioSource.MIC)
            setOutputFormat(MediaRecorder.OutputFormat.MPEG_4)
            setAudioEncoder(MediaRecorder.AudioEncoder.AAC)
            setOutputFile(audioFile?.absolutePath)
            prepare()
            start()
        }

        call.resolve(JSObject().put("status", "recording"))
    }

    @PluginMethod
    fun stopRecording(call: PluginCall) {
        mediaRecorder?.apply {
            stop()
            release()
        }
        mediaRecorder = null

        call.resolve(JSObject()
            .put("status", "stopped")
            .put("filePath", audioFile?.absolutePath))
    }

    @PluginMethod
    fun uploadRecording(call: PluginCall) {
        val userId = call.getString("userId") ?: run {
            call.reject("userId required")
            return
        }

        val requestBody = MultipartBody.Builder()
            .setType(MultipartBody.FORM)
            .addFormDataPart(
                "audio",
                "recording.m4a",
                RequestBody.create(MediaType.parse("audio/m4a"), audioFile!!)
            )
            .build()

        val request = Request.Builder()
            .url("http://127.0.0.1:5001/api/voice/yap")
            .header("X-User-Id", userId)
            .post(requestBody)
            .build()

        OkHttpClient().newCall(request).enqueue(object : Callback {
            override fun onResponse(call: okhttp3.Call, response: Response) {
                val json = JSONObject(response.body()?.string())
                call.resolve(JSObject(json.toString()))
            }

            override fun onFailure(call: okhttp3.Call, e: IOException) {
                call.reject("Upload failed", e)
            }
        })
    }
}
```

**AndroidManifest.xml permissions:**
```xml
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.INTERNET" />
```

---

## üñ•Ô∏è Node.js / Backend Integration

```javascript
// server.js or any Node.js script
const CalOSVoiceClient = require('./sdk/voice-client.js');
const fs = require('fs');

const client = new CalOSVoiceClient({
  baseUrl: 'http://127.0.0.1:5001',
  userId: 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d'
});

// Upload pre-recorded audio file
const audioBuffer = fs.readFileSync('./recording.webm');
const result = await client.transcribe(audioBuffer, 'recording.webm');

console.log('Transcript:', result.data.transcript);
console.log('Project:', result.data.project.project_name);

// Get stats
const stats = await client.getCumulativeStats();
console.log('Total tokens:', stats.data.total_tokens_used);
```

---

## ‚öõÔ∏è React Native / Expo Integration

### Install Dependencies

```bash
npm install expo-av
npm install expo-file-system
```

### Implementation

```javascript
// App.js or VoiceRecorder.js
import React, { useState } from 'react';
import { Button, Text, View } from 'react-native';
import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system';
import CalOSVoiceClient from './sdk/voice-client';

const client = new CalOSVoiceClient({
  baseUrl: 'http://127.0.0.1:5001',
  userId: 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d'
});

export default function VoiceRecorder() {
  const [recording, setRecording] = useState(null);
  const [transcript, setTranscript] = useState('');

  async function startRecording() {
    await Audio.requestPermissionsAsync();
    await Audio.setAudioModeAsync({
      allowsRecordingIOS: true,
      playsInSilentModeIOS: true,
    });

    const { recording } = await Audio.Recording.createAsync(
      Audio.RecordingOptionsPresets.HIGH_QUALITY
    );
    setRecording(recording);
  }

  async function stopRecording() {
    await recording.stopAndUnloadAsync();
    const uri = recording.getURI();

    // Upload to CalOS
    const result = await client.transcribe({ uri }, 'recording.m4a');
    setTranscript(result.data.transcript);

    setRecording(null);
  }

  return (
    <View>
      <Button
        title={recording ? 'Stop Recording' : 'Start Recording'}
        onPress={recording ? stopRecording : startRecording}
      />
      {transcript && <Text>Transcript: {transcript}</Text>}
    </View>
  );
}
```

---

## üêß Linux / Desktop Integration

### Python Client

```python
# voice_client.py
import requests
import sounddevice as sd
import soundfile as sf
import numpy as np

class CalOSVoiceClient:
    def __init__(self, base_url='http://127.0.0.1:5001', user_id=None):
        self.base_url = base_url
        self.user_id = user_id

    def record_audio(self, duration=5, samplerate=16000):
        """Record audio from microphone"""
        print(f"Recording for {duration} seconds...")
        audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1)
        sd.wait()
        return audio, samplerate

    def transcribe(self, audio_file_path):
        """Upload audio file for transcription"""
        with open(audio_file_path, 'rb') as f:
            files = {'audio': ('recording.wav', f, 'audio/wav')}
            headers = {'X-User-Id': self.user_id}

            response = requests.post(
                f'{self.base_url}/api/voice/yap',
                files=files,
                headers=headers
            )

            return response.json()

    def get_stats(self):
        """Get cumulative usage stats"""
        headers = {'X-User-Id': self.user_id}
        response = requests.get(
            f'{self.base_url}/api/voice/stats/cumulative',
            headers=headers
        )
        return response.json()

# Usage
client = CalOSVoiceClient(user_id='e7dc083f-61de-4567-a5b6-b21ddb09cb2d')

# Record
audio, sr = client.record_audio(duration=5)
sf.write('recording.wav', audio, sr)

# Transcribe
result = client.transcribe('recording.wav')
print('Transcript:', result['data']['transcript'])

# Stats
stats = client.get_stats()
print('Total calls:', stats['data']['total_api_calls'])
```

### Install Dependencies

```bash
pip install requests sounddevice soundfile numpy
```

---

## ü™ü Windows / .NET / NuGet Integration

### C# Client

```csharp
// VoiceClient.cs
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Threading.Tasks;
using Newtonsoft.Json;

public class CalOSVoiceClient
{
    private readonly HttpClient _httpClient;
    private readonly string _baseUrl;
    private readonly string _userId;

    public CalOSVoiceClient(string baseUrl = "http://127.0.0.1:5001", string userId = null)
    {
        _baseUrl = baseUrl;
        _userId = userId;
        _httpClient = new HttpClient();
        _httpClient.DefaultRequestHeaders.Add("X-User-Id", _userId);
    }

    public async Task<TranscriptionResult> TranscribeAsync(string audioFilePath)
    {
        using (var content = new MultipartFormDataContent())
        {
            var fileStream = File.OpenRead(audioFilePath);
            var streamContent = new StreamContent(fileStream);
            streamContent.Headers.ContentType = new MediaTypeHeaderValue("audio/webm");
            content.Add(streamContent, "audio", Path.GetFileName(audioFilePath));

            var response = await _httpClient.PostAsync($"{_baseUrl}/api/voice/yap", content);
            var json = await response.Content.ReadAsStringAsync();
            return JsonConvert.DeserializeObject<TranscriptionResult>(json);
        }
    }

    public async Task<UsageStats> GetStatsAsync()
    {
        var response = await _httpClient.GetAsync($"{_baseUrl}/api/voice/stats/cumulative");
        var json = await response.Content.ReadAsStringAsync();
        return JsonConvert.DeserializeObject<UsageStats>(json);
    }
}

public class TranscriptionResult
{
    [JsonProperty("status")]
    public string Status { get; set; }

    [JsonProperty("data")]
    public TranscriptionData Data { get; set; }
}

public class TranscriptionData
{
    [JsonProperty("transcript")]
    public string Transcript { get; set; }

    [JsonProperty("project")]
    public ProjectInfo Project { get; set; }
}

public class ProjectInfo
{
    [JsonProperty("project_name")]
    public string ProjectName { get; set; }

    [JsonProperty("confidence")]
    public double Confidence { get; set; }
}

public class UsageStats
{
    [JsonProperty("data")]
    public UsageData Data { get; set; }
}

public class UsageData
{
    [JsonProperty("total_api_calls")]
    public int TotalApiCalls { get; set; }

    [JsonProperty("total_tokens_used")]
    public int TotalTokens { get; set; }

    [JsonProperty("total_cost_usd")]
    public decimal TotalCost { get; set; }
}
```

### Usage

```csharp
// Program.cs
var client = new CalOSVoiceClient(
    userId: "e7dc083f-61de-4567-a5b6-b21ddb09cb2d"
);

// Transcribe
var result = await client.TranscribeAsync("recording.webm");
Console.WriteLine($"Transcript: {result.Data.Transcript}");
Console.WriteLine($"Project: {result.Data.Project.ProjectName}");

// Stats
var stats = await client.GetStatsAsync();
Console.WriteLine($"Total calls: {stats.Data.TotalApiCalls}");
Console.WriteLine($"Total tokens: {stats.Data.TotalTokens}");
```

### NuGet Packages Required

```bash
dotnet add package Newtonsoft.Json
dotnet add package NAudio  # For audio recording
```

---

## üîê Authentication Methods

### Method 1: Session Cookie (Web Only)

```javascript
// Login first
const loginResponse = await fetch('/auth/login', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    email: 'roughsparks@example.com',
    password: 'your-password'
  })
});

// Cookie is automatically set
// All subsequent requests use cookie authentication
```

### Method 2: X-User-Id Header (All Platforms)

```javascript
// Get user_id from login response or database
const userId = 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d';

// Pass in every request
fetch('/api/voice/yap', {
  headers: {
    'X-User-Id': userId
  }
});
```

### Method 3: SDK (Recommended)

```javascript
const client = new CalOSVoiceClient({
  userId: 'e7dc083f-61de-4567-a5b6-b21ddb09cb2d'
});

// SDK handles authentication automatically
await client.transcribe(audioBlob);
```

---

## üìä Complete API Reference

| Endpoint | Method | Auth | Description |
|----------|--------|------|-------------|
| `/api/voice/projects` | GET | Required | List all projects |
| `/api/voice/yap` | POST | Required | Upload voice recording |
| `/api/voice/transcriptions` | GET | Required | List your transcriptions |
| `/api/voice/stats/cumulative` | GET | Required | All-time usage totals |
| `/api/voice/stats/daily` | GET | Required | Daily usage breakdown |
| `/api/voice/export` | POST | Required | Export to PDF/Markdown |

---

## üß™ Testing Your Integration

### 1. Test API Connectivity

```bash
# Replace YOUR-USER-ID with your actual user_id
curl -H "X-User-Id: YOUR-USER-ID" \
  http://127.0.0.1:5001/api/voice/projects
```

**Expected response:**
```json
{
  "status": "success",
  "data": {
    "total": 7,
    "projects": [...]
  }
}
```

### 2. Test Audio Upload

```bash
# Record a test audio file
# Then upload:
curl -X POST \
  -H "X-User-Id: YOUR-USER-ID" \
  -F "audio=@recording.webm" \
  http://127.0.0.1:5001/api/voice/yap
```

**Expected response:**
```json
{
  "status": "success",
  "data": {
    "transcript": "your speech text here",
    "project": {
      "project_name": "CalOS Platform",
      "confidence": 0.87
    }
  }
}
```

### 3. Test Stats

```bash
curl -H "X-User-Id: YOUR-USER-ID" \
  http://127.0.0.1:5001/api/voice/stats/cumulative
```

---

## üöÄ Production Deployment

### Update Base URLs

**Development:**
```javascript
baseUrl: 'http://127.0.0.1:5001'
```

**Production:**
```javascript
baseUrl: 'https://your-domain.com'
```

### HTTPS Requirements

For production, voice recording requires HTTPS:
- iOS Safari requires HTTPS for microphone access
- Android Chrome requires HTTPS
- Desktop browsers allow HTTP only on localhost

### CORS Configuration

Server already has CORS enabled in `router.js`. For production, update allowed origins:

```javascript
app.use(cors({
  origin: ['https://your-domain.com', 'capacitor://localhost'],
  credentials: true
}));
```

---

## üìö Additional Resources

- **Main Guide**: `VOICE_USAGE_TRACKING_GUIDE.md`
- **SDK Source**: `sdk/voice-client.js`
- **PWA Demo**: `public/voice-recorder.html`
- **API Routes**: `routes/voice-project-routes.js`
- **Database Schema**: `migrations/018_voice_usage_tracking.sql`

---

## ‚ùì Troubleshooting

### "User ID not set" Error

**Solution:** Pass `userId` to SDK or use `X-User-Id` header:
```javascript
client.setUserId('your-user-id-here');
```

### Microphone Permission Denied

**Solution:**
- Web: Browser prompts for permission on first use
- iOS: Add `NSMicrophoneUsageDescription` to `Info.plist`
- Android: Add `RECORD_AUDIO` permission to `AndroidManifest.xml`

### Cannot Connect to Server

**Solution:**
1. Check server is running: `lsof -i:5001`
2. Start server: `npm run start:quiet`
3. Check firewall allows port 5001

### "Failed to upload" Error

**Solution:**
1. Check audio file format (webm, m4a, wav supported)
2. Verify user_id is correct
3. Check server logs: `tail -f /tmp/clean-server.log`

---

**All systems working! üé§üìä**

**Access the PWA now:** http://127.0.0.1:5001/voice-recorder.html
